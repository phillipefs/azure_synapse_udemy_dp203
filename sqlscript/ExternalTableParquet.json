{
	"name": "ExternalTableParquet",
	"properties": {
		"content": {
			"query": "\nCREATE EXTERNAL DATA SOURCE log_data\nWITH (    LOCATION   = 'abfss://data@synapselaketrainning.dfs.core.windows.net',\n          CREDENTIAL = AzureStorageCredential,\n          TYPE = HADOOP\n)\n\n-- Drop the table if it already exists\nDROP EXTERNAL TABLE [logdata]\n\n-- Here we are mentioning the file format as Parquet\n\nCREATE EXTERNAL FILE FORMAT parquetfile  \nWITH (  \n    FORMAT_TYPE = PARQUET,  \n    DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'  \n);\n\n-- Notice that the column names don't contain spaces\n-- When Azure Data Factory was used to generate these files, the column names could not have spaces\n\nCREATE EXTERNAL TABLE [logdata]\n(\n    [Id] [int] NULL,\n\t[Correlationid] [varchar](200) NULL,\n\t[Operationname] [varchar](200) NULL,\n\t[Status] [varchar](100) NULL,\n\t[Eventcategory] [varchar](100) NULL,\n\t[Level] [varchar](100) NULL,\n\t[Time] [datetime] NULL,\n\t[Subscription] [varchar](200) NULL,\n\t[Eventinitiatedby] [varchar](1000) NULL,\n\t[Resourcetype] [varchar](1000) NULL,\n\t[Resourcegroup] [varchar](1000) NULL\n)\nWITH (\n LOCATION = '/parquet/',\n    DATA_SOURCE = log_data,  \n    FILE_FORMAT = parquetfile\n)\n\n/*\nA common error can come when trying to select the data, here you can get various errors such as MalformedInput\n\nYou need to ensure the column names map correctly and the data types are correct as per the parquet file definition\n\n*/\n\n\nSELECT * FROM [logdata]\n\n\nSELECT [Operationname] , COUNT([Operationname]) as [Operation Count]\nFROM [logdata]\nGROUP BY [Operationname]\nORDER BY [Operation Count]\n\n\n",
			"metadata": {
				"language": "sql"
			},
			"currentConnection": {
				"databaseName": "master",
				"poolName": "Built-in"
			},
			"resultLimit": 5000
		},
		"type": "SqlQuery"
	}
}